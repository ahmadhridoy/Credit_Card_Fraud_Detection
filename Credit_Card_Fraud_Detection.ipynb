{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhridoy/Credit_Card_Fraud_Detection/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This Presentation code made by Badar Uddin Ahmad Ridoy, ID:201-115-143\n"
      ],
      "metadata": {
        "id": "78Ed-UFK3CWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing The Neccery Laibaries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "ra5rLF073Qt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset to a Pandas DataFrame\n",
        "\n",
        "df = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "BQOUcW0n4M3V",
        "outputId": "4f324a52-e006-4419-a60e-7d81389bfbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                         1.00713216009241  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425         -0.145619   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166         -0.041910   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103          0.555012   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932         -0.464234   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675         -0.817926   \n",
              "\n",
              "                                                                                                                                                                                                                         -0.0333822827933916  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425            -0.183085   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166            -0.400588   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103            -0.331649   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932            -0.071818   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675            -0.010832   \n",
              "\n",
              "                                                                                                                                                                                                                         0.934756850433034  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425          -0.451572   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166          -0.197064   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103           0.398753   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932           0.005434   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675           1.006890   \n",
              "\n",
              "                                                                                                                                                                                                                         -0.00354577747934159  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425              0.614069   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166             -0.121735   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103              0.220621   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932              0.174650   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675              0.046370   \n",
              "\n",
              "                                                                                                                                                                                                                         0.0878536782832691  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425            0.446065   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166            1.002152   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103           -0.269427   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932            0.092471   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675            0.153534   \n",
              "\n",
              "                                                                                                                                                                                                                         0.244664250472608  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425          -0.022251   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166          -0.130172   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103           0.011147   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932          -0.176257   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675           0.023377   \n",
              "\n",
              "                                                                                                                                                                                                                         0.0917341384438695  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425           -0.006493   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166            0.081019   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103            0.096248   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932            0.069114   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675            0.053558   \n",
              "\n",
              "                                                                                                                                                                                                                           9.03  \\\n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425   11.50   \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166  527.43   \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103  319.53   \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932    7.61   \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675   49.50   \n",
              "\n",
              "                                                                                                                                                                                                                         0  \n",
              "37374.0  1.227686 -0.120287 0.312172  0.591464 -0.250294  0.202008 -0.300560 0.130739  0.498736 -0.037833  0.105918  0.669375 -0.424215  0.026927 -0.971866  0.121180 -0.447235  0.249918  0.789960 -0.102660 -0.113425  0  \n",
              "37375.0  0.113211 -1.978341 0.120060  0.457266 -1.019677  0.687322  0.060754 0.226170  0.393414 -0.387053  1.548102  0.931177 -0.508381  0.332403  0.398505 -0.171043  0.223101 -0.685748 -0.477405  0.900126  0.346166  0  \n",
              "         0.556781 -1.040441 1.082325  1.532471 -1.483066 -0.195038 -0.375717 0.065491  0.730324 -0.125534 -0.630638 -0.260954 -0.530841  0.065002  1.670235  0.884131 -0.725653  0.757554 -0.937478  0.474860  0.431103  0  \n",
              "        -1.337929  1.718734 1.756638  2.751385 -0.201229  0.704670 -0.011846 0.602623 -1.338767  0.885935  0.494714  0.657032  0.332751  0.177797 -0.555753 -0.114036  0.178708  0.264528  1.667389  0.114544 -0.165932  0  \n",
              "        -0.355319  0.371995 0.146324 -0.930711  2.210162  3.804506  0.113916 0.974340 -0.200588 -0.636056 -0.601277 -0.057853 -0.225289 -0.058055 -0.153378  0.047453 -0.480931 -0.078903  0.748166  0.156242 -0.247675  0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc609b80-97e4-402c-99b4-0befc3ada5a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1.00713216009241</th>\n",
              "      <th>-0.0333822827933916</th>\n",
              "      <th>0.934756850433034</th>\n",
              "      <th>-0.00354577747934159</th>\n",
              "      <th>0.0878536782832691</th>\n",
              "      <th>0.244664250472608</th>\n",
              "      <th>0.0917341384438695</th>\n",
              "      <th>9.03</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37374.0</th>\n",
              "      <th>1.227686</th>\n",
              "      <th>-0.120287</th>\n",
              "      <th>0.312172</th>\n",
              "      <th>0.591464</th>\n",
              "      <th>-0.250294</th>\n",
              "      <th>0.202008</th>\n",
              "      <th>-0.300560</th>\n",
              "      <th>0.130739</th>\n",
              "      <th>0.498736</th>\n",
              "      <th>-0.037833</th>\n",
              "      <th>0.105918</th>\n",
              "      <th>0.669375</th>\n",
              "      <th>-0.424215</th>\n",
              "      <th>0.026927</th>\n",
              "      <th>-0.971866</th>\n",
              "      <th>0.121180</th>\n",
              "      <th>-0.447235</th>\n",
              "      <th>0.249918</th>\n",
              "      <th>0.789960</th>\n",
              "      <th>-0.102660</th>\n",
              "      <th>-0.113425</th>\n",
              "      <td>-0.145619</td>\n",
              "      <td>-0.183085</td>\n",
              "      <td>-0.451572</td>\n",
              "      <td>0.614069</td>\n",
              "      <td>0.446065</td>\n",
              "      <td>-0.022251</td>\n",
              "      <td>-0.006493</td>\n",
              "      <td>11.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">37375.0</th>\n",
              "      <th>0.113211</th>\n",
              "      <th>-1.978341</th>\n",
              "      <th>0.120060</th>\n",
              "      <th>0.457266</th>\n",
              "      <th>-1.019677</th>\n",
              "      <th>0.687322</th>\n",
              "      <th>0.060754</th>\n",
              "      <th>0.226170</th>\n",
              "      <th>0.393414</th>\n",
              "      <th>-0.387053</th>\n",
              "      <th>1.548102</th>\n",
              "      <th>0.931177</th>\n",
              "      <th>-0.508381</th>\n",
              "      <th>0.332403</th>\n",
              "      <th>0.398505</th>\n",
              "      <th>-0.171043</th>\n",
              "      <th>0.223101</th>\n",
              "      <th>-0.685748</th>\n",
              "      <th>-0.477405</th>\n",
              "      <th>0.900126</th>\n",
              "      <th>0.346166</th>\n",
              "      <td>-0.041910</td>\n",
              "      <td>-0.400588</td>\n",
              "      <td>-0.197064</td>\n",
              "      <td>-0.121735</td>\n",
              "      <td>1.002152</td>\n",
              "      <td>-0.130172</td>\n",
              "      <td>0.081019</td>\n",
              "      <td>527.43</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.556781</th>\n",
              "      <th>-1.040441</th>\n",
              "      <th>1.082325</th>\n",
              "      <th>1.532471</th>\n",
              "      <th>-1.483066</th>\n",
              "      <th>-0.195038</th>\n",
              "      <th>-0.375717</th>\n",
              "      <th>0.065491</th>\n",
              "      <th>0.730324</th>\n",
              "      <th>-0.125534</th>\n",
              "      <th>-0.630638</th>\n",
              "      <th>-0.260954</th>\n",
              "      <th>-0.530841</th>\n",
              "      <th>0.065002</th>\n",
              "      <th>1.670235</th>\n",
              "      <th>0.884131</th>\n",
              "      <th>-0.725653</th>\n",
              "      <th>0.757554</th>\n",
              "      <th>-0.937478</th>\n",
              "      <th>0.474860</th>\n",
              "      <th>0.431103</th>\n",
              "      <td>0.555012</td>\n",
              "      <td>-0.331649</td>\n",
              "      <td>0.398753</td>\n",
              "      <td>0.220621</td>\n",
              "      <td>-0.269427</td>\n",
              "      <td>0.011147</td>\n",
              "      <td>0.096248</td>\n",
              "      <td>319.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1.337929</th>\n",
              "      <th>1.718734</th>\n",
              "      <th>1.756638</th>\n",
              "      <th>2.751385</th>\n",
              "      <th>-0.201229</th>\n",
              "      <th>0.704670</th>\n",
              "      <th>-0.011846</th>\n",
              "      <th>0.602623</th>\n",
              "      <th>-1.338767</th>\n",
              "      <th>0.885935</th>\n",
              "      <th>0.494714</th>\n",
              "      <th>0.657032</th>\n",
              "      <th>0.332751</th>\n",
              "      <th>0.177797</th>\n",
              "      <th>-0.555753</th>\n",
              "      <th>-0.114036</th>\n",
              "      <th>0.178708</th>\n",
              "      <th>0.264528</th>\n",
              "      <th>1.667389</th>\n",
              "      <th>0.114544</th>\n",
              "      <th>-0.165932</th>\n",
              "      <td>-0.464234</td>\n",
              "      <td>-0.071818</td>\n",
              "      <td>0.005434</td>\n",
              "      <td>0.174650</td>\n",
              "      <td>0.092471</td>\n",
              "      <td>-0.176257</td>\n",
              "      <td>0.069114</td>\n",
              "      <td>7.61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-0.355319</th>\n",
              "      <th>0.371995</th>\n",
              "      <th>0.146324</th>\n",
              "      <th>-0.930711</th>\n",
              "      <th>2.210162</th>\n",
              "      <th>3.804506</th>\n",
              "      <th>0.113916</th>\n",
              "      <th>0.974340</th>\n",
              "      <th>-0.200588</th>\n",
              "      <th>-0.636056</th>\n",
              "      <th>-0.601277</th>\n",
              "      <th>-0.057853</th>\n",
              "      <th>-0.225289</th>\n",
              "      <th>-0.058055</th>\n",
              "      <th>-0.153378</th>\n",
              "      <th>0.047453</th>\n",
              "      <th>-0.480931</th>\n",
              "      <th>-0.078903</th>\n",
              "      <th>0.748166</th>\n",
              "      <th>0.156242</th>\n",
              "      <th>-0.247675</th>\n",
              "      <td>-0.817926</td>\n",
              "      <td>-0.010832</td>\n",
              "      <td>1.006890</td>\n",
              "      <td>0.046370</td>\n",
              "      <td>0.153534</td>\n",
              "      <td>0.023377</td>\n",
              "      <td>0.053558</td>\n",
              "      <td>49.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc609b80-97e4-402c-99b4-0befc3ada5a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc609b80-97e4-402c-99b4-0befc3ada5a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc609b80-97e4-402c-99b4-0befc3ada5a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "av083sCi4r3m",
        "outputId": "70ab06dc-0684-47d5-abd9-c6f4860f2dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                             1.00713216009241  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866          -0.360438   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617          -0.077826   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518          -0.947940   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725          -0.591816   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                      NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             -0.0333822827933916  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866              0.092942   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617              0.056577   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518              0.369640   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725             -0.140595   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                         NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             0.934756850433034  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866            0.536912   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617           -1.008943   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518            0.445435   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725           -0.739479   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                       NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             -0.00354577747934159  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866              -0.600539   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617              -0.290398   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518              -0.356238   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725              -0.333499   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                          NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             0.0878536782832691  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866            -0.059604   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617             0.373463   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518             0.016897   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725            -0.374199   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                        NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             0.244664250472608  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866           -0.318109   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617           -0.033192   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518           -1.064181   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725           -0.167668   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                       NaN   \n",
              "\n",
              "                                                                                                                                                                                                                             0.0917341384438695  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866            -0.144452   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617             0.033956   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518             0.329735   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725            -0.084052   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN                        NaN   \n",
              "\n",
              "                                                                                                                                                                                                                              9.03  \\\n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866   16.00   \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617   44.72   \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518   10.98   \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725   37.95   \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN           NaN   \n",
              "\n",
              "                                                                                                                                                                                                                               0  \n",
              "171397.0 -0.254333  0.494893  0.783833 -0.894191 0.553898 -1.230924 1.161303 -0.393764 -0.193330 -0.294848  1.285844  0.897139 -0.313439  0.119693 -1.430896  0.070111  -0.769782 -0.514484 -0.525843 -0.170387  -0.151866   0.0  \n",
              "171398.0 -0.943864  0.836655  0.292689 -0.723866 0.873360  0.545275 0.710274  0.602397 -0.636504 -1.214351 -0.455679  0.651790  0.303791  0.488004  0.140440 -1.128422   0.782360 -2.156077 -0.997310 -0.193194  -0.017617   0.0  \n",
              "         -2.149728  1.810804 -1.509192 -0.693237 0.415451 -0.875696 0.531266 -0.032141  1.019081  0.718613 -0.915369 -0.386748 -0.612209 -1.092653 -0.034489  0.402806   0.425526 -0.176931 -0.170894 -0.309333  -0.306518   0.0  \n",
              "171399.0 -0.612184  1.263673  2.083651  2.499148 0.825444  0.786503 0.913700 -0.061163 -1.199105  0.779886 -1.913224 -0.815450  0.206096 -0.522099 -0.726729  1.398002  -1.403465 -0.022860 -1.414118 -0.089283  -0.221725   0.0  \n",
              "171400.0  1.209070 -2.338353 -4.422113 -1.100578 2.146988  2.885949 0.657054  0.267981 -1.383349  0.808358 -0.225478 -0.154596 -0.003269  0.000000 NaN       NaN        NaN       NaN       NaN       NaN        NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-651e5ae2-8bad-4c57-926f-3b82de25e658\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1.00713216009241</th>\n",
              "      <th>-0.0333822827933916</th>\n",
              "      <th>0.934756850433034</th>\n",
              "      <th>-0.00354577747934159</th>\n",
              "      <th>0.0878536782832691</th>\n",
              "      <th>0.244664250472608</th>\n",
              "      <th>0.0917341384438695</th>\n",
              "      <th>9.03</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>171397.0</th>\n",
              "      <th>-0.254333</th>\n",
              "      <th>0.494893</th>\n",
              "      <th>0.783833</th>\n",
              "      <th>-0.894191</th>\n",
              "      <th>0.553898</th>\n",
              "      <th>-1.230924</th>\n",
              "      <th>1.161303</th>\n",
              "      <th>-0.393764</th>\n",
              "      <th>-0.193330</th>\n",
              "      <th>-0.294848</th>\n",
              "      <th>1.285844</th>\n",
              "      <th>0.897139</th>\n",
              "      <th>-0.313439</th>\n",
              "      <th>0.119693</th>\n",
              "      <th>-1.430896</th>\n",
              "      <th>0.070111</th>\n",
              "      <th>-0.769782</th>\n",
              "      <th>-0.514484</th>\n",
              "      <th>-0.525843</th>\n",
              "      <th>-0.170387</th>\n",
              "      <th>-0.151866</th>\n",
              "      <td>-0.360438</td>\n",
              "      <td>0.092942</td>\n",
              "      <td>0.536912</td>\n",
              "      <td>-0.600539</td>\n",
              "      <td>-0.059604</td>\n",
              "      <td>-0.318109</td>\n",
              "      <td>-0.144452</td>\n",
              "      <td>16.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">171398.0</th>\n",
              "      <th>-0.943864</th>\n",
              "      <th>0.836655</th>\n",
              "      <th>0.292689</th>\n",
              "      <th>-0.723866</th>\n",
              "      <th>0.873360</th>\n",
              "      <th>0.545275</th>\n",
              "      <th>0.710274</th>\n",
              "      <th>0.602397</th>\n",
              "      <th>-0.636504</th>\n",
              "      <th>-1.214351</th>\n",
              "      <th>-0.455679</th>\n",
              "      <th>0.651790</th>\n",
              "      <th>0.303791</th>\n",
              "      <th>0.488004</th>\n",
              "      <th>0.140440</th>\n",
              "      <th>-1.128422</th>\n",
              "      <th>0.782360</th>\n",
              "      <th>-2.156077</th>\n",
              "      <th>-0.997310</th>\n",
              "      <th>-0.193194</th>\n",
              "      <th>-0.017617</th>\n",
              "      <td>-0.077826</td>\n",
              "      <td>0.056577</td>\n",
              "      <td>-1.008943</td>\n",
              "      <td>-0.290398</td>\n",
              "      <td>0.373463</td>\n",
              "      <td>-0.033192</td>\n",
              "      <td>0.033956</td>\n",
              "      <td>44.72</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2.149728</th>\n",
              "      <th>1.810804</th>\n",
              "      <th>-1.509192</th>\n",
              "      <th>-0.693237</th>\n",
              "      <th>0.415451</th>\n",
              "      <th>-0.875696</th>\n",
              "      <th>0.531266</th>\n",
              "      <th>-0.032141</th>\n",
              "      <th>1.019081</th>\n",
              "      <th>0.718613</th>\n",
              "      <th>-0.915369</th>\n",
              "      <th>-0.386748</th>\n",
              "      <th>-0.612209</th>\n",
              "      <th>-1.092653</th>\n",
              "      <th>-0.034489</th>\n",
              "      <th>0.402806</th>\n",
              "      <th>0.425526</th>\n",
              "      <th>-0.176931</th>\n",
              "      <th>-0.170894</th>\n",
              "      <th>-0.309333</th>\n",
              "      <th>-0.306518</th>\n",
              "      <td>-0.947940</td>\n",
              "      <td>0.369640</td>\n",
              "      <td>0.445435</td>\n",
              "      <td>-0.356238</td>\n",
              "      <td>0.016897</td>\n",
              "      <td>-1.064181</td>\n",
              "      <td>0.329735</td>\n",
              "      <td>10.98</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171399.0</th>\n",
              "      <th>-0.612184</th>\n",
              "      <th>1.263673</th>\n",
              "      <th>2.083651</th>\n",
              "      <th>2.499148</th>\n",
              "      <th>0.825444</th>\n",
              "      <th>0.786503</th>\n",
              "      <th>0.913700</th>\n",
              "      <th>-0.061163</th>\n",
              "      <th>-1.199105</th>\n",
              "      <th>0.779886</th>\n",
              "      <th>-1.913224</th>\n",
              "      <th>-0.815450</th>\n",
              "      <th>0.206096</th>\n",
              "      <th>-0.522099</th>\n",
              "      <th>-0.726729</th>\n",
              "      <th>1.398002</th>\n",
              "      <th>-1.403465</th>\n",
              "      <th>-0.022860</th>\n",
              "      <th>-1.414118</th>\n",
              "      <th>-0.089283</th>\n",
              "      <th>-0.221725</th>\n",
              "      <td>-0.591816</td>\n",
              "      <td>-0.140595</td>\n",
              "      <td>-0.739479</td>\n",
              "      <td>-0.333499</td>\n",
              "      <td>-0.374199</td>\n",
              "      <td>-0.167668</td>\n",
              "      <td>-0.084052</td>\n",
              "      <td>37.95</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171400.0</th>\n",
              "      <th>1.209070</th>\n",
              "      <th>-2.338353</th>\n",
              "      <th>-4.422113</th>\n",
              "      <th>-1.100578</th>\n",
              "      <th>2.146988</th>\n",
              "      <th>2.885949</th>\n",
              "      <th>0.657054</th>\n",
              "      <th>0.267981</th>\n",
              "      <th>-1.383349</th>\n",
              "      <th>0.808358</th>\n",
              "      <th>-0.225478</th>\n",
              "      <th>-0.154596</th>\n",
              "      <th>-0.003269</th>\n",
              "      <th>0.000000</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-651e5ae2-8bad-4c57-926f-3b82de25e658')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-651e5ae2-8bad-4c57-926f-3b82de25e658 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-651e5ae2-8bad-4c57-926f-3b82de25e658');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Information of **Datasets**"
      ],
      "metadata": {
        "id": "JH7oY6qi5ajX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XkPlSDq5IuA",
        "outputId": "405958b7-e2db-4950-b5a7-405ba81626a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiIndex([( 37374.0,   1.22768602136597, -0.120287149081477, ...),\n",
              "            ( 37375.0,  0.113210983088856,  -1.97834142654817, ...),\n",
              "            ( 37375.0,  0.556780757643408,  -1.04044075835739, ...),\n",
              "            ( 37375.0,  -1.33792898390089,    1.7187342228615, ...),\n",
              "            ( 37375.0, -0.355319296261972,  0.371995328434362, ...),\n",
              "            ( 37377.0,   1.15593460309505, 0.0102129188492482, ...),\n",
              "            ( 37378.0,  -2.41491067639733,  -2.62637632534076, ...),\n",
              "            ( 37378.0,   1.16408808114873, 0.0548352156531936, ...),\n",
              "            ( 37378.0,   1.37394751121801, -0.436335137159316, ...),\n",
              "            ( 37379.0,   1.20052827441618, -0.439232869385005, ...),\n",
              "            ...\n",
              "            (171392.0,    2.1816221234042, 0.0311477320211125, ...),\n",
              "            (171394.0, -0.873713982567193,  0.745665210107566, ...),\n",
              "            (171394.0,   1.96102399577712,   -1.2257535871975, ...),\n",
              "            (171396.0, -0.418734124063422,   -4.6509442265675, ...),\n",
              "            (171396.0,  -7.05876841496659,   4.51376717398905, ...),\n",
              "            (171397.0,  -0.25433292459933,  0.494892893203491, ...),\n",
              "            (171398.0,   -0.9438644902757,  0.836654929620706, ...),\n",
              "            (171398.0,  -2.14972829872599,   1.81080412073432, ...),\n",
              "            (171399.0, -0.612184485536639,   1.26367302139809, ...),\n",
              "            (171400.0,   1.20906994646103,   -2.3383531444828, ...)],\n",
              "           length=249385)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtsaq3ky5NPP",
        "outputId": "d9083abe-12ca-47f9-ac9d-f229d5faa77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
              "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
              "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
              "       'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zco9zZ8W5Tun",
        "outputId": "802944b3-3570-4a05-c4e5-ca9d7f945dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjf1MH9o5kjQ",
        "outputId": "5c6f68ec-a51a-437f-a0ab-c21736580e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of missing values in each column\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWXFg_AR6MbB",
        "outputId": "0c5f3143-f4a4-401c-a63c-0f66ca3ae855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of legit transactions & fraudulent transactions\n",
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNzceel-MXGq",
        "outputId": "d063cecc-311f-443f-b345-0697e950f7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Dataset is highly unblanced\n",
        "\n",
        "0 --> Normal Transaction\n",
        "\n",
        "1 --> fraudulent transaction"
      ],
      "metadata": {
        "id": "ZTsYzzKHMpQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data for analysis\n",
        "legit = df[df.Class == 0]\n",
        "fraud = df[df.Class == 1]"
      ],
      "metadata": {
        "id": "0Mu-u-ZEMqfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legit.shape)\n",
        "print(fraud.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8wNXqDQNAj9",
        "outputId": "e45837b5-b212-4ee5-da19-9749b4184592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(284315, 31)\n",
            "(492, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical measures of the data\n",
        "legit.Amount.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGzN1DkxNIsQ",
        "outputId": "b0104681-7586-4b13-9758-a7b7636d3982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    284315.000000\n",
              "mean         88.291022\n",
              "std         250.105092\n",
              "min           0.000000\n",
              "25%           5.650000\n",
              "50%          22.000000\n",
              "75%          77.050000\n",
              "max       25691.160000\n",
              "Name: Amount, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fraud.Amount.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmtlBRtPNLxe",
        "outputId": "d32b2982-e137-4fe7-a300-aa99d06769b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     492.000000\n",
              "mean      122.211321\n",
              "std       256.683288\n",
              "min         0.000000\n",
              "25%         1.000000\n",
              "50%         9.250000\n",
              "75%       105.890000\n",
              "max      2125.870000\n",
              "Name: Amount, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compare the value for the transaction\n",
        "\n",
        "df.groupby('Class').mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "V9BuPkcW4GBJ",
        "outputId": "f26da9a6-abbd-4a59-81aa-8fe55fe8272a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f5da26345283>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#compare the value for the transaction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8400\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8402\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   8403\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8404\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    966\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w_fd3WGNgtE",
        "outputId": "38ef8dbb-39fe-46a2-f56d-507418804a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method IndexOpsMixin.value_counts of 0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "284802    0\n",
              "284803    0\n",
              "284804    0\n",
              "284805    0\n",
              "284806    0\n",
              "Name: Class, Length: 284807, dtype: int64>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('Class', axis = 1)\n",
        "\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "I9i_QSkrOi3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train , x_test , y_train , y_test = train_test_split(x , y, test_size = 0.3 , random_state = 42)\n",
        "\n",
        "print('Shape of x_train:', x_train.shape)\n",
        "print('Shape of x_test:', x_test.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "print('Shape of y_test:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXXsFiB9Oz4n",
        "outputId": "bd0d3810-6c68-4150-e897-471745f0f21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (199364, 30)\n",
            "Shape of x_test: (85443, 30)\n",
            "Shape of y_train: (199364,)\n",
            "Shape of y_test: (85443,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "Xngp8jIUXrHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = [LogisticRegression(), SVC(), KNeighborsClassifier(), RandomForestClassifier(), GaussianNB()]\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for model in models:\n",
        "    model.fit(x_train,y_train)\n",
        "    print(f\"{model.__class__.__name__} train score: {model.score(x_train, y_train):.3f}\")\n",
        "    print(f\"{model.__class__.__name__} test score: {model.score(x_train, y_train):.3f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U43UHsF5V-4U",
        "outputId": "197c2da8-849f-4bbe-c00f-34f277fdce36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression train score: 0.999\n",
            "LogisticRegression test score: 0.999\n",
            "\n",
            "SVC train score: 0.998\n",
            "SVC test score: 0.998\n",
            "\n",
            "KNeighborsClassifier train score: 0.998\n",
            "KNeighborsClassifier test score: 0.998\n",
            "\n",
            "RandomForestClassifier train score: 1.000\n",
            "RandomForestClassifier test score: 1.000\n",
            "\n",
            "GaussianNB train score: 0.993\n",
            "GaussianNB test score: 0.993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Use K-fold cross validation and find the best performing model"
      ],
      "metadata": {
        "id": "DyVHjZoFWyWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import cross validation funnction\n",
        "\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "0IgzkC_OkQDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross validetion code\n",
        "\n",
        "for model in models:\n",
        "  cv_score = cross_val_score(model , x , y ,cv=5)\n",
        "  mean_accuracy = sum(cv_score)/len(cv_score)\n",
        "  mean_accuracy = mean_accuracy*100\n",
        "  mean_accuracy = round(mean_accuracy , 3)\n",
        "\n",
        "  print('Cross Validation Accuracies for the ', model, '=', cv_score)\n",
        "  print('Accuracy score of the ', model , '=' , mean_accuracy, '%')\n",
        "\n",
        "  print('------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "9CHlF7hMkXfP",
        "outputId": "87501462-fe39-46f4-afbb-c96f5b558350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Accuracies for the  LogisticRegression() = [0.98239177 0.99964889 0.99901687 0.99915732 0.99866575]\n",
            "Accuracy score of the  LogisticRegression() = 99.578 %\n",
            "------------------------------------------\n",
            "Cross Validation Accuracies for the  SVC() = [0.998262   0.998262   0.99827952 0.99827952 0.99827952]\n",
            "Accuracy score of the  SVC() = 99.827 %\n",
            "------------------------------------------\n",
            "Cross Validation Accuracies for the  KNeighborsClassifier() = [0.0304589  0.27836101 0.53468162 0.41814575 0.99827952]\n",
            "Accuracy score of the  KNeighborsClassifier() = 45.199 %\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-62991a254245>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmean_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmean_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_accuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}